{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NER Dataset Creation Notebook**\n",
    "\n",
    "This notebook demonstrates the process of **creating a dataset** for the Named Entity Recognition (NER) task.  \n",
    "We will:\n",
    "1. Define or generate text samples containing mountain names.\n",
    "2. Annotate these texts with NER labels (e.g., `MOUNTAIN`).\n",
    "3. Convert them into a format suitable for further training.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# CELL 1: Import Libraries\n",
    "# ---\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Mountain Names\n",
    "\n",
    "Below, we list some well-known mountain names. In a real project, you could expand this list significantly or replace it with ones specific to your domain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# CELL 2: Define a list of mountain names\n",
    "# ---\n",
    "mountain_names = [\n",
    "    \"Mount Everest\", \"K2\", \"Kangchenjunga\", \"Lhotse\", \"Makalu\",\n",
    "    \"Cho Oyu\", \"Dhaulagiri\", \"Manaslu\", \"Annapurna\", \"Nanga Parbat\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Sentences\n",
    "\n",
    "We can create synthetic sentences that mention these mountains.  \n",
    "In a real-world scenario, you might collect text from articles, books, or other sources and then annotate them manually or with a semi-automated approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have always dreamed of climbing Mount Everest.\n",
      "Lhotse and Nanga Parbat are both on my bucket list.\n",
      "I have always dreamed of climbing K2.\n",
      "I have always dreamed of climbing Nanga Parbat.\n",
      "Mount Everest and Nanga Parbat are both on my bucket list.\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# CELL 3: Generate Synthetic Sentences\n",
    "# ---\n",
    "def generate_sentences(mountains, num_samples=20):\n",
    "    \"\"\"\n",
    "    Generate synthetic sentences mentioning random mountains from the given list.\n",
    "    \n",
    "    Args:\n",
    "        mountains (list): A list of mountain names.\n",
    "        num_samples (int): Number of synthetic sentences to generate.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of synthetic sentences.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    for _ in range(num_samples):\n",
    "        num_mtns = random.randint(1, 2)  # Randomly choose how many mountains to mention\n",
    "        chosen = random.sample(mountains, num_mtns)\n",
    "        \n",
    "        if len(chosen) == 1:\n",
    "            sentence = f\"I have always dreamed of climbing {chosen[0]}.\"\n",
    "        else:\n",
    "            sentence = f\"{chosen[0]} and {chosen[1]} are both on my bucket list.\"\n",
    "        \n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "synthetic_sentences = generate_sentences(mountain_names, num_samples=30)\n",
    "\n",
    "# Let's preview a few sentences\n",
    "for s in synthetic_sentences[:5]:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Annotate the Text for NER\n",
    "\n",
    "We need to annotate each mention of a mountain with the label `MOUNTAIN`.  \n",
    "We'll do this by searching for exact matches of the mountain names in the generated sentences (a simple approach).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I have always dreamed of climbing Mount Everest.', {'entities': [(34, 47, 'MOUNTAIN')]})\n",
      "('Lhotse and Nanga Parbat are both on my bucket list.', {'entities': [(0, 6, 'MOUNTAIN'), (11, 23, 'MOUNTAIN')]})\n",
      "('I have always dreamed of climbing K2.', {'entities': [(34, 36, 'MOUNTAIN')]})\n",
      "('I have always dreamed of climbing Nanga Parbat.', {'entities': [(34, 46, 'MOUNTAIN')]})\n",
      "('Mount Everest and Nanga Parbat are both on my bucket list.', {'entities': [(0, 13, 'MOUNTAIN'), (18, 30, 'MOUNTAIN')]})\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# CELL 4: Annotate the Text\n",
    "# ---\n",
    "def annotate_text(sentences, mountains):\n",
    "    \"\"\"\n",
    "    Annotate each sentence by identifying mountain mentions and \n",
    "    storing the character start, end indices, and label.\n",
    "    \n",
    "    Args:\n",
    "        sentences (list): List of text strings.\n",
    "        mountains (list): List of mountain names.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tuples (sentence, {\"entities\": [...]})\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for sentence in sentences:\n",
    "        entities = []\n",
    "        for mountain in mountains:\n",
    "            # Use re.finditer to find all occurrences of a mountain name in the sentence\n",
    "            # re.escape to handle special regex characters in mountain names\n",
    "            matches = list(re.finditer(re.escape(mountain), sentence))\n",
    "            for match in matches:\n",
    "                start, end = match.span()\n",
    "                entities.append((start, end, \"MOUNTAIN\"))\n",
    "        \n",
    "        # Sort entities by start position (good practice for some NER frameworks)\n",
    "        entities = sorted(entities, key=lambda x: x[0])\n",
    "        \n",
    "        training_data.append((sentence, {\"entities\": entities}))\n",
    "    return training_data\n",
    "\n",
    "training_data = annotate_text(synthetic_sentences, mountain_names)\n",
    "\n",
    "# Let's see how a few annotated samples look\n",
    "for item in training_data[:5]:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Converting to spaCy's `DocBin` Format\n",
    "\n",
    "spaCy can store training data in the `DocBin` format. This section shows how to:\n",
    "1. Load a spaCy model (to create `Doc` objects).\n",
    "2. Convert the annotated data into `Doc` objects.\n",
    "3. Save them as a `.spacy` file for easy loading during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy DocBin dataset saved to: ner_mountain_dataset.spacy\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# CELL 5: Convert the Training Data to DocBin\n",
    "# ---\n",
    "def create_spacy_docbin(nlp, data):\n",
    "    \"\"\"\n",
    "    Convert annotated data into a spaCy DocBin object.\n",
    "    \n",
    "    Args:\n",
    "        nlp (Language): A loaded spaCy language model (to create Doc objects).\n",
    "        data (list): The annotated data in the format [(text, {\"entities\": [...]})].\n",
    "        \n",
    "    Returns:\n",
    "        DocBin: A DocBin object containing the docs with entity annotations.\n",
    "    \"\"\"\n",
    "    doc_bin = DocBin()\n",
    "    for text, annot in data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        \n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is None:\n",
    "                # If span creation fails (overlapping entities or invalid indices),\n",
    "                # skip or handle accordingly.\n",
    "                continue\n",
    "            ents.append(span)\n",
    "        \n",
    "        doc.ents = ents\n",
    "        doc_bin.add(doc)\n",
    "    return doc_bin\n",
    "\n",
    "# We can load a small spaCy pipeline or a blank model for doc creation.\n",
    "# For English, let's use a lightweight blank model:\n",
    "nlp_blank = spacy.blank(\"en\")\n",
    "\n",
    "doc_bin = create_spacy_docbin(nlp_blank, training_data)\n",
    "doc_bin.to_disk(\"ner_mountain_dataset.spacy\")\n",
    "\n",
    "print(\"SpaCy DocBin dataset saved to: ner_mountain_dataset.spacy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (Optional) Convert to CSV or Any Other Format\n",
    "\n",
    "Depending on your workflow, you might also want to export the dataset to CSV or JSON for inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV dataset saved to: ner_mountain_dataset.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have always dreamed of climbing Mount Everest.</td>\n",
       "      <td>[(34, 47, MOUNTAIN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lhotse and Nanga Parbat are both on my bucket ...</td>\n",
       "      <td>[(0, 6, MOUNTAIN), (11, 23, MOUNTAIN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have always dreamed of climbing K2.</td>\n",
       "      <td>[(34, 36, MOUNTAIN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have always dreamed of climbing Nanga Parbat.</td>\n",
       "      <td>[(34, 46, MOUNTAIN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mount Everest and Nanga Parbat are both on my ...</td>\n",
       "      <td>[(0, 13, MOUNTAIN), (18, 30, MOUNTAIN)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   I have always dreamed of climbing Mount Everest.   \n",
       "1  Lhotse and Nanga Parbat are both on my bucket ...   \n",
       "2              I have always dreamed of climbing K2.   \n",
       "3    I have always dreamed of climbing Nanga Parbat.   \n",
       "4  Mount Everest and Nanga Parbat are both on my ...   \n",
       "\n",
       "                                  entities  \n",
       "0                     [(34, 47, MOUNTAIN)]  \n",
       "1   [(0, 6, MOUNTAIN), (11, 23, MOUNTAIN)]  \n",
       "2                     [(34, 36, MOUNTAIN)]  \n",
       "3                     [(34, 46, MOUNTAIN)]  \n",
       "4  [(0, 13, MOUNTAIN), (18, 30, MOUNTAIN)]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---\n",
    "# CELL 6: (Optional) Save to CSV\n",
    "# ---\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"text\": text,\n",
    "        \"entities\": annot[\"entities\"]\n",
    "    }\n",
    "    for text, annot in training_data\n",
    "])\n",
    "df.to_csv(\"ner_mountain_dataset.csv\", index=False)\n",
    "\n",
    "print(\"CSV dataset saved to: ner_mountain_dataset.csv\")\n",
    "\n",
    "# Quick preview\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "- We **generated synthetic sentences** mentioning mountain names.\n",
    "- We **annotated** them with a `MOUNTAIN` label.\n",
    "- We **converted** the annotated data into:\n",
    "  - A **spaCy DocBin** format (`.spacy`) for easy integration with spaCy training scripts.\n",
    "  - A **CSV file** for quick inspection.\n",
    "\n",
    "This concludes the dataset creation process for our **NER** task.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
